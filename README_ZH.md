# Coupang Scraper

此專案是一個網頁爬蟲工具，旨在根據特定搜尋詞從電商網站提取商品信息。該工具自動化了資料收集與整理的過程，便於進一步分析。

## 目錄

- [環境設置](#環境設置)
- [使用方法](#使用方法)
  - [擷取腳本](#擷取腳本)
  - [搜尋詞準備](#搜尋詞準備)
  - [參數設置](#參數設置)
- [爬蟲資料提交](#爬蟲資料提交)
  - [需提取的商品資訊](#需提取的商品資訊)
  - [資料儲存格式](#資料儲存格式)
  - [檔案命名規則](#檔案命名規則)
  - [提交全部資料](#提交全部資料)
- [重要注意事項](#重要注意事項)
  - [爬蟲注意事項](#爬蟲注意事項)
## 環境設置

執行以下指令以安裝必要模組

```bash
pip install -r requirements.txt
```

## 使用方法

### 爬蟲程式

完整的爬蟲程式位於 `scraper.ipynb` 文件中，從頭開始依序執行即可。

### 搜尋詞準備

您可以使用提供的搜尋詞 `./queries/M11207321_queries.txt`，或自行準備搜尋詞。

如果您想使用自訂的搜尋詞，請確保搜尋詞保存於一個`.txt檔`中，並且`每行一個搜尋詞`：

```
筆電
衣服
餅乾
洗衣精
衛生紙
...
```

### 參數設置

打開 `scraper.ipynb` ，找到 **Parameter Setting** 部分。在這裡，您可以定義或修改以下參數：

1. **student_id**: 您的學號。
2. **query_path**: 搜尋詞的路徑。
3. **results_path**: 保存爬蟲結果的路徑。
4. **search_url**: 要爬取的電商網站網址（必須是台灣的 Coupang 頁面）。
5. **short_time_sleep**: 等待時間(短)。
6. **medium_time_sleep**: 等待時間(中)。
7. **long_time_sleep**: 等待時間(長)。

## 爬蟲資料提交

### 需提取的商品資訊

在爬蟲的過程中，請確保收集以下商品信息：

1. **商品名稱**
2. **商品價格**
3. **商品連結**

### 資料儲存格式

將收集的數據保存為 `.csv` 文件，並包含以下欄位：

1. **product_name**: 商品名稱
2. **product_price**: 商品價格
3. **product_url**: 商品連結

請確保 `.csv` 文件編碼為 **UTF-8-SIG**。

### 檔案命名規則

在爬取每個搜尋詞的商品資料後，請使用以下檔案命名規則保存結果：`StudentID_QueryName.csv` ，ex: `M11207321_口罩.csv`（如果您的學生證號包含字母，請使用大寫字母）。

### 提交全部資料

如果需要提交爬蟲資料，請將所有搜尋詞的結果文件放入一個以您的 `學號` 命名的資料夾中，然後將該資料夾壓縮成一個 `學號zip`，ex: `M11207321.zip`（如果學號包含字母，請使用大寫字母）。

## 重要注意事項

### 爬蟲注意事項
- 爬蟲時，可以開啟其他視窗，但**請勿關閉、縮小正在爬蟲的 chrome 視窗**（重要）
- 爬蟲時，確保**螢幕是維持開啟的**（重要）